{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0027472972869873047\n",
      "测试成功!\n",
      "输入形状: input_xyz_aug_proj_f1=torch.Size([1, 16, 1800, 3]), input_points_f1=torch.Size([1, 16, 1800, 3]),l0_xyz_proj_f1=torch.Size([1, 4, 225, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from typing import List, Dict, Optional, Tuple, Callable\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "H_input=16\n",
    "W_input=1800\n",
    "batch_size=1\n",
    "Down_conv_dis = [0.75, 3.0, 6.0, 12.0]\n",
    "Up_conv_dis = [3.0, 6.0, 9.0]\n",
    "Cost_volume_dis = [1.0, 2.0, 4.5]\n",
    "\n",
    "stride_H_list = [4, 2, 2, 1]\n",
    "stride_W_list = [8, 2, 2, 2]\n",
    "\n",
    "out_H_list = [math.ceil( H_input /  stride_H_list[0])]\n",
    "out_W_list = [math.ceil( W_input /  stride_W_list[0])]\n",
    "\n",
    "\n",
    "def PreProcess(PC_f1):    ####    pre process procedure\n",
    "\n",
    "        batch_size = len(PC_f1)\n",
    "        PC_f1_concat = []\n",
    "        PC_f1_aft_aug = []\n",
    "\n",
    "        for p in PC_f1:\n",
    "            \n",
    "            num_points = torch.tensor(p.shape[0], dtype=torch.int32)\n",
    "            add_T = torch.ones(num_points, 1).cuda().to(torch.float32)\n",
    "            PC_f1_add = torch.cat([p, add_T], -1)  ##  concat one to form   n 4\n",
    "            PC_f1_concat.append(PC_f1_add)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(batch_size):\n",
    "\n",
    "\n",
    "            cur_PC_f1_concat = PC_f1_concat[i]\n",
    "   \n",
    "            ##  select the 20m * 20m region ########\n",
    "            r_f1 = torch.norm(cur_PC_f1_concat[:, :2], p=2, dim =1, keepdim = True).repeat(1, 4)\n",
    "            cur_PC_f1_concat = torch.where( r_f1 > 20 , torch.zeros_like(cur_PC_f1_concat).cuda(), cur_PC_f1_concat ).to(torch.float32)\n",
    "            PC_mask_valid1 = torch.any(cur_PC_f1_concat != 0, dim=-1).cuda().detach()  # H W\n",
    "            cur_PC_f1_concat = cur_PC_f1_concat[PC_mask_valid1 > 0,:]\n",
    "\n",
    "\n",
    "\n",
    "            #####   generate  the  valid  mask (remove the not valid points)\n",
    "            mask_valid_f1 = torch.any(cur_PC_f1_concat != 0, dim=-1, keepdim=True).cuda().detach()  # N 1\n",
    "            mask_valid_f1 = mask_valid_f1.to(torch.float32)\n",
    "\n",
    "           \n",
    "\n",
    "            cur_PC_f1_concat = cur_PC_f1_concat[:, :3]\n",
    "            cur_PC_f1_mask = cur_PC_f1_concat * mask_valid_f1 # N 3\n",
    "\n",
    "            PC_f1_aft_aug.append(cur_PC_f1_mask)### list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return PC_f1_aft_aug\n",
    "\n",
    "\n",
    "def ProjectPCimg2SphericalRing(PC, Feature = None, H_input = 64, W_input = 1800):\n",
    "\n",
    "    \n",
    "    batch_size = len(PC)\n",
    "\n",
    "    if Feature != None:\n",
    "        num_channel = Feature[0].shape[-1]\n",
    "\n",
    "    degree2radian = math.pi / 180\n",
    "    nLines = H_input\n",
    "    AzimuthResolution = 360.0 / W_input # degree\n",
    "    VerticalViewDown = -35.0\n",
    "    VerticalViewUp = 35.0\n",
    "\n",
    "    # specifications of Velodyne-64\n",
    "    AzimuthResolution = AzimuthResolution * degree2radian\n",
    "    VerticalViewDown = VerticalViewDown * degree2radian\n",
    "    VerticalViewUp = VerticalViewUp * degree2radian\n",
    "    VerticalResolution = (VerticalViewUp - VerticalViewDown) / (nLines - 1)\n",
    "    VerticalPixelsOffset = -VerticalViewDown / VerticalResolution\n",
    "\n",
    "    # parameters for spherical ring's bounds\n",
    "\n",
    "    PI = math.pi\n",
    "\n",
    "    for batch_idx in range(batch_size):\n",
    "\n",
    "        ###  initialize current processed frame\n",
    "\n",
    "        cur_PC = PC[batch_idx].to(torch.float32)  # N  3\n",
    "        # print(cur_PC.shape)\n",
    "        if Feature != None:\n",
    "            cur_Feature = Feature[batch_idx]  # N  c\n",
    "\n",
    "        x = cur_PC[:, 0]\n",
    "        y = cur_PC[:, 1]\n",
    "        z = cur_PC[:, 2]\n",
    "\n",
    "        r = torch.norm(cur_PC, p=2, dim =1)\n",
    "\n",
    "        PC_project_current = torch.zeros([H_input, W_input, 3]).cuda().detach()  # shape H W 3\n",
    "        if Feature != None:\n",
    "            Feature_project_current = torch.zeros([H_input, W_input, num_channel]).cuda().detach()\n",
    "\n",
    "        \n",
    "\n",
    "        ####  get iCol & iRow\n",
    "\n",
    "        iCol = ((PI -torch.atan2(y, x))/ AzimuthResolution) # alpha\n",
    "        iCol = iCol.to(torch.int32)\n",
    "\n",
    "        beta = torch.asin(z/r)                              # beta\n",
    "\n",
    "        tmp_int = (beta / VerticalResolution + VerticalPixelsOffset)\n",
    "        tmp_int = tmp_int.to(torch.int32)\n",
    "\n",
    "        iRow = H_input - tmp_int\n",
    "\n",
    "        iRow = torch.clamp(iRow, 0, H_input - 1)\n",
    "        iCol = torch.clamp(iCol, 0, W_input - 1)\n",
    "\n",
    "        iRow = iRow.to(torch.long)  # N 1\n",
    "        iCol = iCol.to(torch.long)  # N 1\n",
    "\n",
    "\n",
    "        PC_project_current[iRow, iCol, :] = cur_PC[:, :]  # H W 3\n",
    "        if Feature != None:\n",
    "            Feature_project_current[iRow, iCol, :] = cur_Feature[:, :]\n",
    "\n",
    "\n",
    "        # Generate mask\n",
    "\n",
    "        PC_mask_valid = torch.any(PC_project_current != 0, dim=-1).cuda().detach()  # H W\n",
    "        PC_mask_valid = torch.unsqueeze(PC_mask_valid, dim=2).to(torch.float32) # H W 1\n",
    "\n",
    "        if Feature != None:\n",
    "            Feature_mask_valid = ~torch.any(Feature_project_current!= 0, dim=-1).cuda().detach()  # H W\n",
    "            Feature_mask_valid = torch.unsqueeze(Feature_mask_valid, dim=2).to(torch.float32)\n",
    "\n",
    "        ####1 h w\n",
    "        PC_project_current = torch.unsqueeze(PC_project_current, dim=0)\n",
    "        PC_mask_valid = torch.unsqueeze(PC_mask_valid, dim=0)\n",
    "\n",
    "\n",
    "        if Feature != None:\n",
    "            Feature_project_current = torch.unsqueeze(Feature_project_current,dim=0)\n",
    "            Feature_mask_valid = torch.unsqueeze(Feature_mask_valid, dim=0)\n",
    "        ####b h w\n",
    "        if batch_idx == 0:\n",
    "            PC_project_final = PC_project_current\n",
    "            PC_mask_final = PC_mask_valid\n",
    "            if Feature != None:\n",
    "                Feature_project_final = Feature_project_current\n",
    "                Feature_mask_final = Feature_mask_valid\n",
    "\n",
    "        else:\n",
    "            PC_project_final = torch.cat([PC_project_final, PC_project_current], 0)  # b h w 3\n",
    "            PC_mask_final = torch.cat([PC_mask_final, PC_mask_valid], 0)\n",
    "            if Feature != None:\n",
    "                Feature_project_final = torch.cat([Feature_project_final, Feature_project_current], 0)\n",
    "                Feature_mask_final = torch.cat([Feature_mask_final, Feature_mask_valid], 0)\n",
    "\n",
    "\n",
    "    if Feature != None:\n",
    "        return PC_project_final,  Feature_project_final\n",
    "    else:\n",
    "        return PC_project_final,  PC_mask_final\n",
    "\n",
    "\n",
    "\n",
    "def get_selected_idx(batch_size, out_H: int, out_W: int, stride_H: int, stride_W: int):\n",
    "    \"\"\"According to given stride and output size, return the corresponding selected points\n",
    "\n",
    "    Args:\n",
    "        array (tf.Tensor): [any array with shape (B, H, W, 3)]\n",
    "        stride_H (int): [stride in height]\n",
    "        stride_W (int): [stride in width]\n",
    "        out_H (int): [height of output array]\n",
    "        out_W (int): [width of output array]\n",
    "    Returns:\n",
    "        [tf.Tensor]: [shape (B, outh, outw, 3) indices]\n",
    "    \"\"\"\n",
    "    select_h_idx = torch.arange(0, out_H * stride_H, stride_H)\n",
    "    select_w_idx = torch.arange(0, out_W * stride_W, stride_W)\n",
    "    height_indices = (torch.reshape(select_h_idx, (1, -1, 1))).expand(batch_size, out_H, out_W)         # b out_H out_W\n",
    "    width_indices = (torch.reshape(select_w_idx, (1, 1, -1))).expand(batch_size, out_H, out_W)            # b out_H out_W\n",
    "    padding_indices = torch.reshape(torch.arange(batch_size), (-1, 1, 1)).expand(batch_size, out_H, out_W)   # b out_H out_W\n",
    "\n",
    "    return padding_indices, height_indices, width_indices    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "points =torch.randn(100000,3).to('cuda')\n",
    "points=30*points\n",
    "\n",
    "pos1_list = []\n",
    "pos1_list.append(points)\n",
    " #pos1_list.append(points)\n",
    " \n",
    " #with torch.no_grad():\n",
    "     \n",
    " #    predictions,_,_ =  model(points)\n",
    "t2=time.time()    \n",
    "input_xyz_aug_f1= PreProcess(pos1_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_xyz_aug_proj_f1, mask_xyz_f1 = ProjectPCimg2SphericalRing(input_xyz_aug_f1, None, H_input,  W_input)\n",
    " \n",
    " \n",
    "\n",
    "l0_b_idx, l0_h_idx, l0_w_idx = get_selected_idx(batch_size, out_H_list[0],\n",
    "    out_W_list[0],  stride_H_list[0],\n",
    "    stride_W_list[0])\n",
    " \n",
    "\n",
    "t1=time.time()\n",
    "print(t1-t2)\n",
    "\n",
    "\n",
    "\n",
    "input_points_f1 = torch.zeros_like(input_xyz_aug_proj_f1).cuda()\n",
    "l0_xyz_proj_f1 = input_xyz_aug_proj_f1[l0_b_idx.cuda().long(),l0_h_idx.cuda().long(), l0_w_idx.cuda().long(), :]\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " #new_points, new_xyz =  model(input_xyz_aug_proj_f1, input_points_f1, l0_xyz_proj_f1)\n",
    " #new_points =  model(input_xyz_aug_proj_f1, input_points_f1, l0_xyz_proj_f1)\n",
    "     \n",
    "\n",
    "\n",
    "print(\"测试成功!\")\n",
    "print(f\"输入形状: input_xyz_aug_proj_f1={input_xyz_aug_proj_f1.shape}, input_points_f1={input_points_f1.shape},l0_xyz_proj_f1={l0_xyz_proj_f1.shape}\")\n",
    " #print(f\"输出形状: new_points={new_points.shape}\")\n",
    " \n",
    "\"\"\"\n",
    " \n",
    " 输入形状: input_xyz_aug_proj_f1=torch.Size([1, 64, 1800, 3]), input_points_f1=torch.Size([1, 64, 1800, 3]),l0_xyz_proj_f1=torch.Size([1, 16, 225, 3])\n",
    " 输出形状: new_points=torch.Size([1, 16])\n",
    "\n",
    " \n",
    "\"\"\"\n",
    "   \n",
    "\n",
    " #\"\"\"\n",
    "\n",
    "input_xyz_aug_proj_f1=input_xyz_aug_proj_f1[:,:,600:1200,:]\n",
    "mask_xyz_f1=mask_xyz_f1[:,:,600:1200,:]\n",
    "im_numpy = input_xyz_aug_proj_f1.squeeze(0).cpu().numpy()\n",
    "im_mask = mask_xyz_f1.squeeze(0).cpu().numpy()\n",
    "\n",
    " #\"\"\"\n",
    "\n",
    "  \n",
    " \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " # Here you would process the predictions and publish the segmented point cloud\n",
    " # For simplicity, we just publish the original point cloud\n",
    " # segmented_cloud_pub.publish(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nomad_train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
